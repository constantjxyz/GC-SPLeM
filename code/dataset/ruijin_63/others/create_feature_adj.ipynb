{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import h5py\n",
    "from sklearn.metrics.pairwise import cosine_similarity, paired_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGraph:\n",
    "    def __init__(self, nodes, embedding_matrix):\n",
    "        super(EmbeddingGraph).__init__()\n",
    "        self.nodes = np.array(nodes, dtype=object)\n",
    "        self.nodes_num = len(nodes)\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.adj_matrix = np.zeros(shape = (self.nodes_num, self.nodes_num), dtype=float)\n",
    "        self.distance_matrix = np.zeros_like(self.adj_matrix)\n",
    "        self.degrees= self.adj_matrix.sum(1)\n",
    "    \n",
    "    def preprocess(self):\n",
    "        estimator = PCA(n_components=32)\n",
    "        pca = estimator.fit_transform(self.embedding_matrix)\n",
    "        self.embedding_matrix = pca\n",
    "        scaler = StandardScaler().fit(self.embedding_matrix)\n",
    "        self.embedding_matrix = scaler.transform(self.embedding_matrix)\n",
    "        return self.embedding_matrix\n",
    "\n",
    "    def cal_eucli_distance(self, node_idx1, node_idx2):\n",
    "        '''calculate the euclidean distance between two given nodes' index'''\n",
    "        embedding1 = self.embedding_matrix[node_idx1]\n",
    "        embedding2 = self.embedding_matrix[node_idx2]\n",
    "        eucli_dist = np.sqrt(sum((embedding1 - embedding2) ** 2))\n",
    "        return eucli_dist\n",
    "\n",
    "    def cal_cosine_distance(self, node_idx1, node_idx2):\n",
    "        embedding1 = self.embedding_matrix[node_idx1].reshape(1, -1)\n",
    "        embedding2 = self.embedding_matrix[node_idx2].reshape(1, -1)\n",
    "        cosine_dist = paired_distances(embedding1, embedding2, metric='cosine')\n",
    "        return cosine_dist\n",
    "\n",
    "    def create_distance_matrix(self, mode='cosine'):\n",
    "        '''create distance matrix according to specified standard'''\n",
    "        assert mode in ['eculidean', 'cosine']\n",
    "        for i in range(self.nodes_num):\n",
    "            for j in range(i, self.nodes_num):\n",
    "                if mode == 'eculidean':\n",
    "                    dist = self.cal_eucli_distance(i, j)\n",
    "                elif mode == 'cosine':\n",
    "                    dist = self.cal_cosine_distance(i, j)\n",
    "                self.distance_matrix[i, j] = dist\n",
    "                self.distance_matrix[j, i] = dist\n",
    "        return self.distance_matrix\n",
    "\n",
    "    def knn_create_adj_matrix(self, k):\n",
    "        '''create adj matrix according to k nearest neighbours'''\n",
    "        assert self.distance_matrix.sum() != 0   # need to create distance matrix first, call class.create_distance_matrix()\n",
    "        self.adj_matrix = np.zeros(shape = (self.nodes_num, self.nodes_num), dtype=float) \n",
    "        for i in range(self.nodes_num):\n",
    "            min_k_indices = self.distance_matrix[i].argpartition(k)[:k]\n",
    "            for j in min_k_indices:\n",
    "                self.adj_matrix[i][j] = 1\n",
    "                self.adj_matrix[j][i] = 1\n",
    "        self.degrees = self.adj_matrix.sum(1)\n",
    "        return self.adj_matrix\n",
    "    \n",
    "    def embedding_out(self, name, mode='csv'):\n",
    "        assert mode in ['csv', 'tsv']    # output the embedding matrix as a csv file or tsv file\n",
    "        if mode == 'tsv':\n",
    "            np.savetxt(name, self.embedding_matrix, delimiter='\\t')\n",
    "    \n",
    "    def norm_adj_matrix(self):\n",
    "        '''return lapalacian-normed adj matrix'''\n",
    "        assert self.distance_matrix.sum != 0 # need to create distance matrix first, call class.create_distance_matrix() \n",
    "        assert self.adj_matrix.sum() != 0 # need to create adj matrix first, call class.create_adj_matrix() \n",
    "        degree = np.array(self.adj_matrix.sum(1))\n",
    "        self.degrees = degree\n",
    "        degree = np.diag(np.power(degree, -0.5))\n",
    "        return degree.dot(self.adj_matrix).dot(degree)\n",
    "\n",
    "\n",
    "    def save_h5_file(self, name): \n",
    "        if os.path.exists(name):   # replace the old h5 file\n",
    "            os.remove(name)\n",
    "        dt_str = h5py.special_dtype(vlen=str)\n",
    "        f = h5py.File(name, mode='w')\n",
    "        f.create_dataset('nodes', data=self.nodes, dtype=dt_str)\n",
    "        f.create_dataset('embedding_matrix', data=self.embedding_matrix, dtype=float)\n",
    "        f.create_dataset('adj_matrix', data=self.adj_matrix, dtype=float)\n",
    "        f.create_dataset('distance_matrix', data=self.distance_matrix, dtype=float)\n",
    "        normed_adj_matrix = self.norm_adj_matrix()\n",
    "        f.create_dataset('normed_adj_matrix', data=np.array(normed_adj_matrix), dtype=float)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adj table for gnn   \n",
    "patho_gene_embedding_dir = '/amax/data/ruijin/embedding/ruijin_63/splita/'     \n",
    "    # embedding dir on your own device, need to be checked\n",
    "split_file_dir = '/home/xieyuzhang/mtmcat/dataset/survival/ruijin_63/ruijin_63_new_splits/incomplete_dataset.csv'\n",
    "split_file = pd.read_csv(split_file_dir)\n",
    "train_patient_list = list(split_file['train'].dropna())\n",
    "val_patient_list = list(split_file['validation'].dropna())\n",
    "test_patient_list = list(split_file['test'].dropna())\n",
    "case_ids = np.array(train_patient_list + val_patient_list + test_patient_list)\n",
    "patho_gene_embeddings = []\n",
    "for case_id in case_ids:\n",
    "    embedding = np.array(torch.load(os.path.join(patho_gene_embedding_dir, case_id+'.pt')).to('cpu').squeeze(), dtype=float)\n",
    "    patho_gene_embeddings.append(embedding)\n",
    "patho_gene_embeddings = np.array(patho_gene_embeddings)\n",
    "person_graph = EmbeddingGraph(case_ids, patho_gene_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_graph = EmbeddingGraph(case_ids, patho_gene_embeddings)\n",
    "# person_graph.preprocess()\n",
    "person_graph.create_distance_matrix(mode='cosine')\n",
    "person_graph.knn_create_adj_matrix(4)\n",
    "adj = person_graph.norm_adj_matrix()\n",
    "person_graph.save_h5_file('/home/xieyuzhang/mtmcat/dataset/survival/ruijin_63/inputs/embedding/incomplete_dataset/incomplete_dataset_person.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 4., 8., 4., 5., 4., 5., 5., 5., 4., 7., 6., 5., 4., 4., 6.,\n",
       "       4., 4., 5., 4., 4., 4., 4., 5., 4., 4., 4., 4., 5., 5., 4., 4., 4.,\n",
       "       6., 9., 6., 6., 4., 6., 5., 5., 5., 5., 4., 4., 4., 5., 8., 5., 5.,\n",
       "       5., 5., 4., 5., 5., 5., 6., 6., 5., 5., 5., 4.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_graph.degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_graph.embedding_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "68cc5682ddbb5f1d8292668cda43725a2d1c20c4994555d2818af5f2c6072c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
